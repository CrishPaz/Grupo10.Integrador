#!/bin/bash

# Script de backup para Sistema de Salud Laboral

set -e

echo "ðŸ’¾ Iniciando backup del Sistema de Salud Laboral"

# Variables
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="backups/$TIMESTAMP"
# Configura tu bucket real aquÃ­ o dÃ©jalo asÃ­ si solo usarÃ¡s backup local
S3_BUCKET="salud-laboral-backups" 

# Crear directorio de backup
mkdir -p $BACKUP_DIR

echo "ðŸ“¦ Creando backup de base de datos..."
# Nota: AsegÃºrate que el nombre del servicio en docker-compose coincida (ej: salud_db o postgres)
docker-compose exec -T salud_db pg_dump -U admin_salud --format=custom salud_laboral > $BACKUP_DIR/db_backup.dump

# Nota: Si tienes carpetas de uploads, descomenta las siguientes lÃ­neas
# echo "ðŸ“ Creando backup de uploads..."
# cp -r uploads $BACKUP_DIR/

# echo "ðŸ“ Creando backup de logs..."
# cp -r logs $BACKUP_DIR/

echo "ðŸ“‹ Creando archivo de metadatos..."
cat > $BACKUP_DIR/metadata.json << EOF
{
 "timestamp": "$TIMESTAMP",
 "system": "Salud Laboral",
 "version": "1.0.0",
 "database_size": "$(du -h $BACKUP_DIR/db_backup.dump | cut -f1)"
}
EOF

# Comprimir backup
echo "ðŸ—œï¸ Comprimiendo backup..."
tar -czf $BACKUP_DIR.tar.gz -C backups $TIMESTAMP

# Subir a S3 (si estÃ¡ configurado y tienes AWS CLI instalado)
if [ -n "$AWS_ACCESS_KEY_ID" ]; then
  echo "â˜ï¸ Subiendo backup a S3..."
  # aws s3 cp $BACKUP_DIR.tar.gz s3://$S3_BUCKET/$TIMESTAMP.tar.gz
  echo "SimulaciÃ³n: Backup subido a S3"
fi

# Limpiar backups antiguos (mantener Ãºltimos 7 dÃ­as)
echo "ðŸ§¹ Limpiando backups antiguos locales..."
# find backups -type d -name "202*" -mtime +7 -exec rm -rf {} \;
# find backups -type f -name "*.tar.gz" -mtime +7 -delete

echo "âœ… Backup completado exitosamente en: $BACKUP_DIR.tar.gz"